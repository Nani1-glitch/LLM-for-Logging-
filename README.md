# LLM-for-Logging

## ðŸ“– How to Use

### Clone the Repository
```sh
git clone https://github.com/Nani1-glitch/LLM-for-Logging-.git

# Navigate to the Project Directory
cd LLM-for-Logging

Run the Jupyter Notebooks
Final Implementation: Final.ipynb
Manual Log Categorization Examples: Manual Approach(EX).ipynb
Training BERT from Scratch: Trained Bert Model from scratch.ipynb
ðŸ§© Key Components
Data Preprocessing
Log Parsing: Extracts relevant information from raw log files.
Labeling: Identifies and labels error messages.
Model Training
BERT Model: Utilizes BERT for sequence classification.
Training Loop: Implements a custom training loop with logging.
Evaluation
Metrics: Computes accuracy, precision, recall, and F1-score.
Outputs
Trained Model: Saves the trained BERT model and tokenizer.
Evaluation Results: Displays performance metrics of the trained model.
ðŸ“ˆ Results
Evaluation Metrics
Accuracy: 63.97%
Precision: 63.01%
Recall: 67.65%
F1 Score: 65.25%
ðŸ“‚ Data Files
Logs: cisco_log.txt, sample_logs.txt
Enhanced Logs: enhanced_cisco_logs.csv
Structured Logs: structured_logs.csv
Structured Output: structured_output.csv
ðŸ›  Tools & Libraries
Programming Language: Python
Libraries: Pandas, PyTorch, Transformers, Scikit-Learn
ðŸ“œ License
This project is licensed under the MIT License. See the LICENSE file for details.

ðŸ‘¥ Contributing
Contributions are welcome! Please open an issue or submit a pull request.

ðŸ“ž Contact
For any questions or feedback, please contact me!
